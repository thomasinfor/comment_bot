{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot-keras",
      "provenance": [],
      "collapsed_sections": [
        "VKDm5lpKXEmG",
        "_Oi_aInof_ny",
        "MlbxbSWQ1IAi",
        "7GQ91fNYsJ0Y",
        "O0TSWex6n4vE",
        "SlQFLIp7cnhO"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVN8vbz4om2i"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V5PnzB6pOlF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "08232798-fb00-4c2e-ace8-3aaedbf30f11"
      },
      "source": [
        "with open('/content/drive/My Drive/YTP/dialog-ptt.txt') as f:\n",
        "    dialog=f.readlines()\n",
        "n=len(dialog)\n",
        "print(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "774114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDuwoap9ohhk",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# import numpy as np\n",
        "# temp = np.load('/content/drive/My Drive/YTP/ptt_training.npz',allow_pickle=True)\n",
        "# x_train,y_train=temp['x'],temp['y']\n",
        "# # x_train=np.load('/content/drive/My Drive/YTP/ptt_stop_training_x.npy',allow_pickle=True)\n",
        "# # y_train=np.load('/content/drive/My Drive/YTP/ptt_stop_training_y.npy',allow_pickle=True)\n",
        "# wvs=250\n",
        "# n=len(x_train)\n",
        "# v_start=x_train[0][0]\n",
        "# v_end=x_train[0][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz98Wn05vAQE",
        "cellView": "form"
      },
      "source": [
        "#@title padding\n",
        "wvs=250\n",
        "n=len(x_train)\n",
        "v_start=x_train[0][0]\n",
        "v_end=x_train[0][-1]\n",
        "maxx,maxy=0,0\n",
        "for line in x_train:\n",
        "    maxx=max(maxx,len(line))\n",
        "for line in y_train:\n",
        "    maxy=max(maxy,len(line))\n",
        "maxx,maxy=50,30\n",
        "for i in range(n):\n",
        "    while len(x_train[i])<maxx:\n",
        "        x_train[i].append(v_end)\n",
        "    while len(y_train[i])<maxy:\n",
        "        y_train[i].append(v_end)\n",
        "    if len(x_train[i])!=maxx:\n",
        "        print(i,'x',len(x_train[i]))\n",
        "    if len(y_train[i])!=maxy:\n",
        "        print(i,'y',len(y_train[i]))\n",
        "print(x_train.shape,y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSx_xqyjcjq9"
      },
      "source": [
        "# word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp78DpNLXLAv"
      },
      "source": [
        "## data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkBgzXpYoUOD",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "batch_size=320\n",
        "def data_gen(rang=None):\n",
        "    if rang==None:\n",
        "        rang=n\n",
        "    while True:\n",
        "        ind=np.random.randint(0,n,size=(batch_size))\n",
        "        x1,x2,y=[],[],[]\n",
        "        for i in ind:\n",
        "            x1.append(x_train[i])\n",
        "            x2.append(y_train[i])\n",
        "            y.append(np.append(y_train[i][1:],[v_end],axis=0))\n",
        "        yield ([np.array(x1),np.array(x2)],np.array(y))\n",
        "t=data_gen()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9j_1bS0Lcww"
      },
      "source": [
        "d=next(t)\n",
        "print(d[0][0].shape)\n",
        "print(d[0][1].shape)\n",
        "print(d[1].shape)\n",
        "print([int(np.array_equal(i,v_end)) for i in d[0][1][0]])\n",
        "print([int(np.array_equal(i,v_end)) for i in d[1][0]])\n",
        "print([int(np.array_equal(i,v_end)) for i in d[0][1][1]])\n",
        "print([int(np.array_equal(i,v_end)) for i in d[1][1]])\n",
        "print([int(np.array_equal(i,v_end)) for i in d[0][1][2]])\n",
        "print([int(np.array_equal(i,v_end)) for i in d[1][2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKDm5lpKXEmG"
      },
      "source": [
        "## [example](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckImAAkS0hjz"
      },
      "source": [
        "from keras.layers import Dense,LSTM,Activation,RepeatVector,Input,Masking\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "maxx,maxy=40,40\n",
        "v_end=np.zeros((250,))\n",
        "v_start=np.ones((250,))\n",
        "wvs=250\n",
        "input_layer1 = Input((maxx,wvs))\n",
        "x = Masking(v_end)(input_layer1)\n",
        "x = LSTM(1024,return_sequences=True)(x)\n",
        "x,sh,sc = LSTM(1024,return_state=True)(x)\n",
        "\n",
        "input_layer2 = Input((maxy,wvs))\n",
        "x = Masking(v_end)(input_layer2)\n",
        "x = LSTM(1024,return_sequences=True)(x,initial_state=[sh,sc])\n",
        "output_layer = LSTM(wvs,return_sequences=True)(x)\n",
        "model = Model([input_layer1,input_layer2],output_layer)\n",
        "model.compile(loss='mse',optimizer=Adam())\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vmI4emL-gWe"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv5I6Xmm-mdR"
      },
      "source": [
        "from keras.models import load_model\n",
        "model=load_model('/content/drive/My Drive/YTP/instructions.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJvBAS8I-xen"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QBTaCdYV0JV"
      },
      "source": [
        "gen=data_gen()\n",
        "model.fit_generator(gen,epochs=50,steps_per_epoch=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3Xsh-tfLn7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ee94523-899b-4f63-ca46-fa8e9e52a621"
      },
      "source": [
        "model.evaluate_generator(data_gen(),steps=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49007850885391235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Oi_aInof_ny"
      },
      "source": [
        "## sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn40oJTif_No",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "00ddb3cc-3e65-4ebe-bb88-11e1dbfa114a"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import jieba\n",
        "temp = Word2Vec.load('/content/drive/My Drive/YTP/ptt+wiki.model')\n",
        "w2v=temp.wv\n",
        "v_start=w2v['<start>']\n",
        "v_end=w2v['<end>']\n",
        "jieba.set_dictionary('/content/drive/My Drive/YTP/dict.txt')\n",
        "stopword_set = set()\n",
        "# with open('/content/drive/My Drive/stopwords.txt','r',encoding='utf-8') as stopwords:\n",
        "#     for stopword in stopwords:\n",
        "#         stopword_set.add(stopword.strip('\\n'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BxK3WlR69h-"
      },
      "source": [
        "def v2w(vec):\n",
        "    text=[]\n",
        "    for i in range(len(vec)):\n",
        "        text.append(w2v.most_similar(positive=[vec[i]])[0][0])\n",
        "    return text\n",
        "def sample(question,model):\n",
        "    words=jieba.cut(question, cut_all=False)\n",
        "    sentence=[v_start]\n",
        "    for word in words:\n",
        "        if word.isspace():\n",
        "            continue\n",
        "        if word not in stopword_set:\n",
        "            if word in w2v.vocab:\n",
        "                sentence.append(w2v[word])\n",
        "    while len(sentence)<maxx:\n",
        "        sentence.append(v_end)\n",
        "    if len(sentence)!=maxx:\n",
        "        print('too long')\n",
        "        return\n",
        "    ans=[v_start]\n",
        "    state=[v_end for _ in range(maxy)]\n",
        "    state[0]=v_start\n",
        "    for i in range(0,maxy-1):\n",
        "        # print(v2w(state))\n",
        "        # print('------')\n",
        "        pre=model.predict([[sentence],[state]])[0]\n",
        "        state[i+1]=pre[i]\n",
        "        ans.append(pre[i])\n",
        "    text=[]\n",
        "    for i in range(maxy):\n",
        "        text.append(w2v.most_similar(positive=[ans[i]])[0][0])\n",
        "    print(text)\n",
        "    return ans\n",
        "ans=sample('求掛',model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQY5bfIY1FXa"
      },
      "source": [
        "from keras.models import load_model\n",
        "model=load_model('/content/drive/My Drive/YTP/instructions.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKpgWhI-1U04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bb98c19-a1e5-41d5-bfb3-1d34ed81eca7"
      },
      "source": [
        "print(model.output_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlbxbSWQ1IAi"
      },
      "source": [
        "## cool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7XBrLx9qq_C"
      },
      "source": [
        "from keras.layers import Dense,LSTM,Input\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "wvs=250\n",
        "latent_dim = 512\n",
        "encoder_inputs = Input(shape=(None, wvs))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, wvs))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(wvs)\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='cosine_proximity'')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dux12hCKrRsS"
      },
      "source": [
        "gen=data_gen(20)\n",
        "model.fit_generator(gen,epochs=50,steps_per_epoch=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTmUEd6l6Tlq"
      },
      "source": [
        "model.save('/content/drive/My Drive/instructions.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GQ91fNYsJ0Y"
      },
      "source": [
        "## sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ48L6Bhi0G4",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "from gensim.models import Word2Vec\n",
        "import jieba\n",
        "temp = Word2Vec.load('/content/drive/My Drive/ptt+wiki.model')\n",
        "w2v=temp.wv\n",
        "v_start=w2v['<start>']\n",
        "v_end=w2v['<end>']\n",
        "jieba.set_dictionary('/content/drive/My Drive/dict.txt')\n",
        "stopword_set = set()\n",
        "with open('/content/drive/My Drive/stopwords.txt','r',encoding='utf-8') as stopwords:\n",
        "    for stopword in stopwords:\n",
        "        stopword_set.add(stopword.strip('\\n'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOMiuCTbrTQ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fd5cbc95-097e-469a-a55c-3b3a928b3aa6"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "\n",
        "def decode_sequence(question):\n",
        "    words=jieba.cut(question, cut_all=False)\n",
        "    sentence=[v_start]\n",
        "    for word in words:\n",
        "        if word.isspace():\n",
        "            continue\n",
        "        if word not in stopword_set:\n",
        "            if word in w2v.vocab:\n",
        "                sentence.append(w2v[word])\n",
        "    while len(sentence)<maxx:\n",
        "        sentence.append(v_end)\n",
        "    if len(sentence)!=maxx:\n",
        "        print('too long for the question')\n",
        "        return\n",
        "    input_seq=np.array([sentence])\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, wvs))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = v_start\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = '<start>'\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_vector = output_tokens\n",
        "        sampled_char = w2v.most_similar(positive=[sampled_token_vector[0][0]])[0][0]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '<end>' or\n",
        "           len(decoded_sentence) > maxy):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, wvs))\n",
        "        target_seq[0, 0] = sampled_token_vector\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "print(decode_sequence('機車推出uber或計程機車會怎樣ㄐㄣ'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<start>?,,,,,??<end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUN2fNxkD1fy",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "with open('/content/drive/My Drive/Gossiping-QA-Dataset-2_0.csv') as f:\n",
        "    for i,j in enumerate(f.readlines()):\n",
        "        if i not in range(0,30):\n",
        "            continue\n",
        "        print(j,end='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0TSWex6n4vE"
      },
      "source": [
        "## not teacher forcing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iftcy71sqVk-"
      },
      "source": [
        "batch_size=320\n",
        "def data_gen(rang=None):\n",
        "    if rang==None:\n",
        "        rang=n\n",
        "    while True:\n",
        "        ind = np.random.randint(0,rang,batch_size)\n",
        "        x2 = np.zeros((batch_size, 1, wvs))\n",
        "        x2[:, 0] = v_start\n",
        "        x1=[]\n",
        "        y=[]\n",
        "        for i in ind:\n",
        "            x1.append(np.array(x_train[i]))\n",
        "            y.append(np.array(y_train[i][1:]))\n",
        "        # y=np.array(y_train[ind][1:])\n",
        "        yield [np.array(x1),x2],np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKHnWgzn0UZ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3d9de9ed-fc44-42dc-9113-ce19f6c50ee7"
      },
      "source": [
        "t=data_gen()\n",
        "a=next(t)\n",
        "print(a[0][0].shape)\n",
        "print(a[0][1].shape)\n",
        "print(a[1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320, 40, 250)\n",
            "(320, 1, 250)\n",
            "(320, 39, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWOh2Gq4n5Mg",
        "cellView": "both"
      },
      "source": [
        "from keras.layers import Lambda,Input,Dense,LSTM\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "latent_dim = 512\n",
        "wvs=250\n",
        "maxy=40\n",
        "# The first part is unchanged\n",
        "encoder_inputs = Input(shape=(None, wvs))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, which will only process one timestep at a time.\n",
        "decoder_inputs = Input(shape=(1, wvs))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_dense = Dense(wvs)\n",
        "\n",
        "all_outputs = []\n",
        "inputs = decoder_inputs\n",
        "for _ in range(maxy-1):\n",
        "    # Run the decoder on one timestep\n",
        "    outputs, state_h, state_c = decoder_lstm(inputs,\n",
        "                                             initial_state=states)\n",
        "    outputs = decoder_dense(outputs)\n",
        "    # Store the current prediction (we will concatenate all predictions later)\n",
        "    all_outputs.append(outputs)\n",
        "    # Reinject the outputs as inputs for the next loop iteration\n",
        "    # as well as update the states\n",
        "    inputs = outputs\n",
        "    states = [state_h, state_c]\n",
        "\n",
        "# Concatenate all predictions\n",
        "decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "\n",
        "# Define and compile model as previously\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='Adam', loss='cosine_proximity')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHPCaLQFLA9K"
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/YTP/not_teacher_forcing_version.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3diXO8hsS07"
      },
      "source": [
        "gen=data_gen(10)\n",
        "train_model.fit_generator(gen,epochs=30,steps_per_epoch=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUDQHWmb9017"
      },
      "source": [
        "model.save('/content/drive/My Drive/not_teacher_forcing_version.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS9FKFpI9l0p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0efd04c9-f2b7-4628-c264-5b224566a350"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import jieba\n",
        "w2v=KeyedVectors.load('/content/drive/My Drive/YTP/ptt+wiki.kv', mmap='r')\n",
        "v_start=w2v['<start>']\n",
        "v_end=w2v['<end>']\n",
        "jieba.set_dictionary('/content/drive/My Drive/YTP/dict.txt')\n",
        "stopword_set = set()\n",
        "# with open('/content/drive/My Drive/stopwords.txt','r',encoding='utf-8') as stopwords:\n",
        "#     for stopword in stopwords:\n",
        "#         stopword_set.add(stopword.strip('\\n'))\n",
        "def v2w(vec):\n",
        "    text=[]\n",
        "    for i in range(len(vec)):\n",
        "        text.append(w2v.most_similar(positive=[vec[i]])[0][0])\n",
        "    return text\n",
        "def compose(texts):\n",
        "    s = ''\n",
        "    for i in texts:\n",
        "        if i=='<start>':\n",
        "            continue\n",
        "        elif i=='<end>':\n",
        "            return s\n",
        "        else:\n",
        "            s=s+i\n",
        "    return s\n",
        "def str2vs(string):\n",
        "    words=jieba.cut(string, cut_all=False)\n",
        "    sentence=[v_start]\n",
        "    for word in words:\n",
        "        if word.isspace():\n",
        "            continue\n",
        "        if word not in stopword_set:\n",
        "            if word in w2v.vocab:\n",
        "                sentence.append(w2v[word])\n",
        "    while len(sentence)<maxx:\n",
        "        sentence.append(v_end)\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWsIsVh1AepE"
      },
      "source": [
        "print(compose(str2vs('早安')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua3fdKte9mKs"
      },
      "source": [
        "t=data_gen(10)\n",
        "a=next(t)\n",
        "ans=model.predict(a[0])\n",
        "for i in range(10):\n",
        "    print('Q:',compose(v2w(a[0][0][i])))\n",
        "    print('A:',compose(v2w(ans[i])))\n",
        "    print('T:',compose(v2w(a[1][i])))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlQFLIp7cnhO"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5EMqxxDnyQY",
        "cellView": "both"
      },
      "source": [
        "#@title model\n",
        "# new\n",
        "from keras.layers import Lambda,Input,Dense,LSTM\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "\n",
        "latent_dim = 512\n",
        "wvs=250\n",
        "maxx,maxy=50,30\n",
        "\n",
        "IN=Input((maxx,wvs))\n",
        "OUT=IN\n",
        "OUT=LSTM(latent_dim,return_sequences=True)(OUT)\n",
        "OUT=LSTM(latent_dim,return_sequences=True)(OUT)\n",
        "OUT=LSTM(latent_dim,return_sequences=True)(OUT)\n",
        "OUT,state_h,state_c=LSTM(latent_dim,return_state=True)(OUT)\n",
        "encoder=Model(IN,[state_h,state_c])\n",
        "\n",
        "depth=2\n",
        "IN=[Input(shape=(1, wvs))]\n",
        "for i in range(depth-1):\n",
        "    IN+=[Input(shape=(latent_dim,)),Input(shape=(latent_dim,))]\n",
        "IN+=[Input(shape=(wvs,)),Input(shape=(wvs,))]\n",
        "OUT=[None]\n",
        "out=IN[0]\n",
        "for i in range(depth-1):\n",
        "    out,state_h,state_c=LSTM(latent_dim,return_sequences=True,return_state=True)(out,initial_state=IN[i*2+1:i*2+3])\n",
        "    OUT+=[state_h,state_c]\n",
        "out,state_h,state_c=LSTM(wvs,return_sequences=True,return_state=True)(out,initial_state=IN[-2:])\n",
        "OUT+=[state_h,state_c]\n",
        "OUT[0]=out\n",
        "decoder=Model(IN,OUT)\n",
        "\n",
        "IN=[Input(shape=(1, wvs)),Input(shape=(latent_dim,)),Input(shape=(latent_dim,))]\n",
        "OUT=[None]\n",
        "out=IN[0]\n",
        "for i in range(depth-1):\n",
        "    if i==0:\n",
        "        out,state_h,state_c=LSTM(latent_dim,return_sequences=True,return_state=True)(out,initial_state=IN[1:3])\n",
        "    else:\n",
        "        out,state_h,state_c=LSTM(latent_dim,return_sequences=True,return_state=True)(out)\n",
        "    OUT+=[state_h,state_c]\n",
        "out,state_h,state_c=LSTM(wvs,return_sequences=True,return_state=True)(out)\n",
        "OUT+=[state_h,state_c]\n",
        "OUT[0]=out\n",
        "decoder_init=Model(IN,OUT)\n",
        "\n",
        "IN=[Input((maxx,wvs)),Input((1,wvs))]\n",
        "OUT=[]\n",
        "out=encoder(IN[0])\n",
        "for i in range(maxy-1):\n",
        "    if i==0:\n",
        "        temp=decoder_init([IN[1]]+out)\n",
        "    else:\n",
        "        temp=decoder(out)\n",
        "    OUT.append(temp[0])\n",
        "    out=temp\n",
        "\n",
        "OUT=Lambda(lambda x: K.concatenate(x, axis=1))(OUT)\n",
        "train_model=Model(IN,OUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-D17JyYDsC8"
      },
      "source": [
        "train_model.compile(optimizer=Adam(),loss='cosine_proximity')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L7GXOLYDdXk"
      },
      "source": [
        "import numpy as np\n",
        "import jieba\n",
        "from gensim.models import KeyedVectors\n",
        "w2v=KeyedVectors.load('/content/drive/My Drive/YTP/ptt+wiki-stop.kv',mmap='r')\n",
        "v_start=w2v['<start>']\n",
        "v_end=w2v['<end>']\n",
        "jieba.set_dictionary('/content/drive/My Drive/YTP/dict.txt')\n",
        "batch_size=32\n",
        "def to_vec(text):\n",
        "    text=text.strip('\\n')\n",
        "    words=jieba.cut(text,cut_all=False)\n",
        "    res=[]\n",
        "    for word in words:\n",
        "        if word in w2v.vocab:\n",
        "            res.append(w2v[word])\n",
        "    return res\n",
        "\n",
        "def data_gen(rang=None):\n",
        "    if rang==None:\n",
        "        rang=n\n",
        "    while True:\n",
        "        ind=np.random.randint(0,rang,size=batch_size)\n",
        "        # print(ind)\n",
        "        x1,x2,y=[],[],[]\n",
        "        for i in ind:\n",
        "            q,a=dialog[i].split('\\t')\n",
        "            x1.append([v_start]+to_vec(q)+[v_end])\n",
        "            x2.append([v_start])\n",
        "            y.append(to_vec(a)+[v_end])\n",
        "        for i in x1:\n",
        "            while len(i)<maxx:\n",
        "                i.append(v_end)\n",
        "        for i in y:\n",
        "            while len(i)<maxy-1:\n",
        "                i.append(v_end)\n",
        "        yield ([np.array(x1),np.array(x2)],np.array(y))\n",
        "t=data_gen()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZsX-BE6EfMn"
      },
      "source": [
        "gen=data_gen(10)\n",
        "history=train_model.fit_generator(gen,epochs=10,steps_per_epoch=100,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4SWb0UEDcci"
      },
      "source": [
        "train_model.evaluate_generator(gen,steps=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdARN5ypHiyg"
      },
      "source": [
        "train_model.save('/content/drive/My Drive/YTP/deep-model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlVPAH70Rzk_"
      },
      "source": [
        "train_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxIC7w8dfDQ1"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import jieba\n",
        "w2v=KeyedVectors.load('/content/drive/My Drive/YTP/word2vec_with_stop.kv',mmap='r')\n",
        "v_start=w2v['<start>']\n",
        "v_end=w2v['<end>']\n",
        "jieba.set_dictionary('/content/drive/My Drive/YTP/dict.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6Az2lGelUD8"
      },
      "source": [
        "def sample(question):\n",
        "    def v2w(x):\n",
        "        return w2v.most_similar(positive=[x])[0][0]\n",
        "    words=jieba.cut(question,cut_all=False)\n",
        "    sentence=[v_start]\n",
        "    for word in words:\n",
        "        if word.isspace():\n",
        "            continue\n",
        "        if word in w2v.vocab:\n",
        "            sentence.append(w2v[word])\n",
        "    while len(sentence)<maxx:\n",
        "        sentence.append(v_end)\n",
        "    if len(sentence)!=maxx:\n",
        "        print('too long for the question')\n",
        "        return None\n",
        "    ans=[v_start]\n",
        "    text=['<start>']\n",
        "    pre=train_model.predict([[sentence],[[v_start]]])\n",
        "    for i in pre[0]:\n",
        "        text.append(v2w(i))\n",
        "    # pre=encoder.predict(np.array([sentence]))\n",
        "    # IN=[[[v_start]]]+[[i[0]] for i in pre]\n",
        "    # IN=decoder_init.predict(IN)\n",
        "    # ans.append(IN[0][0][0])\n",
        "    # text.append(v2w(IN[0][0][0]))\n",
        "    # for i in range(maxy-2):\n",
        "    #     IN=decoder.predict(IN)\n",
        "    #     ans.append(IN[0][0][0])\n",
        "    #     text.append(v2w(IN[0][0][0]))\n",
        "    #     if text[-1]=='<end>':\n",
        "    #         break\n",
        "    return ' '.join(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvVne_sRwjOb"
      },
      "source": [
        "ans=sample('為什麼達摩祖師傳那麼好看?')\n",
        "print(ans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRdlujJOUlBV"
      },
      "source": [
        "train_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbsIO_FjK-Rg"
      },
      "source": [
        "for i in range(20):\n",
        "    print(dialog[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYXGYkvOVp84"
      },
      "source": [
        "# teacher forcing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa_bnAXAVpLy",
        "cellView": "form"
      },
      "source": [
        "#@title model\n",
        "# new\n",
        "from keras.layers import Lambda,Input,Dense,LSTM,Dropout,TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam,RMSprop\n",
        "import keras.backend as K\n",
        "\n",
        "latent_dim = 1024\n",
        "wvs=250\n",
        "maxx,maxy=30,30\n",
        "rate=0.3\n",
        "\n",
        "IN=Input((maxx,wvs))\n",
        "OUT=IN\n",
        "OUT=Dropout(rate)(OUT)\n",
        "OUT=TimeDistributed(Dense(latent_dim))(OUT)\n",
        "OUT=Dropout(rate)(OUT)\n",
        "OUT,sh,sc=LSTM(latent_dim,return_state=True)(OUT)\n",
        "\n",
        "yIN=Input((maxy,wvs))\n",
        "OUT=LSTM(latent_dim,return_sequences=True)(yIN,initial_state=[sh,sc])\n",
        "OUT=Dropout(rate)(OUT)\n",
        "OUT=TimeDistributed(Dense(wvs))(OUT)\n",
        "\n",
        "model=Model([IN,yIN],OUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRwXLLUMaNe-"
      },
      "source": [
        "model.compile(optimizer=RMSprop(),loss='cosine_proximity')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V50jFDNXaYFs"
      },
      "source": [
        "import numpy as np\n",
        "import jieba\n",
        "from gensim.models import KeyedVectors\n",
        "w2v=KeyedVectors.load('/content/drive/My Drive/YTP/ptt+wiki.kv',mmap='r')\n",
        "v_start=w2v['<start>']\n",
        "v_end=w2v['<end>']\n",
        "jieba.set_dictionary('/content/drive/My Drive/YTP/dict.txt')\n",
        "stop_set=set()\n",
        "with open('/content/drive/My Drive/YTP/stopwords.txt','r',encoding='utf-8') as stopwords:\n",
        "    for stopword in stopwords:\n",
        "        stop_set.add(stopword.strip('\\n'))\n",
        "batch_size=32\n",
        "def to_vec(text):\n",
        "    text=text.strip('\\n')\n",
        "    words=jieba.cut(text,cut_all=False)\n",
        "    res=[]\n",
        "    for word in words:\n",
        "        if word in w2v.vocab and word not in stop_set:\n",
        "            res.append(w2v[word])\n",
        "    return res\n",
        "\n",
        "def data_gen(rang=None):\n",
        "    if rang==None:\n",
        "        rang=n\n",
        "    while True:\n",
        "        ind=np.random.randint(0,rang,size=batch_size)\n",
        "        # print(ind)\n",
        "        x1,x2,y=[],[],[]\n",
        "        for i in ind:\n",
        "            q,a=dialog[i].split('\\t')\n",
        "            q,a=to_vec(q),to_vec(a)\n",
        "            x1.append([v_start]+q+[v_end])\n",
        "            x2.append([v_start]+a+[v_end])\n",
        "            y.append(a+[v_end])\n",
        "        for i in x1:\n",
        "            while len(i)<maxx:\n",
        "                i.append(v_end)\n",
        "        for i in x2:\n",
        "            while len(i)<maxy:\n",
        "                i.append(v_end)\n",
        "        for i in y:\n",
        "            while len(i)<maxy:\n",
        "                i.append(v_end)\n",
        "        yield ([np.array(x1),np.array(x2)],np.array(y))\n",
        "t=data_gen()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o6PQhf0aU-U"
      },
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "datas=1000\n",
        "gen=data_gen(datas)\n",
        "def sample(epoch,log):\n",
        "    if (epoch+1)%5!=0:\n",
        "        return\n",
        "    for _ in range(3):\n",
        "        i=np.random.randint(datas)\n",
        "        print('============')\n",
        "        print('Q:',dialog[i].split('\\t')[0])\n",
        "        print('A:',dialog[i].split('\\t')[1],end='')\n",
        "        print('a:',predict(dialog[i].split('\\t')[0],model))\n",
        "history=model.fit_generator(gen,epochs=200,steps_per_epoch=100,verbose=1,\n",
        "                            callbacks=[LambdaCallback(on_epoch_end=sample)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRau8Fqve_jy"
      },
      "source": [
        "model.save('/content/drive/My Drive/YTP/simple-model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOOukW3qmy3i"
      },
      "source": [
        "from keras.models import load_model\n",
        "model=load_model('/content/drive/My Drive/YTP/simple-model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKkHX-_8m8Ht"
      },
      "source": [
        "model.summary(line_length=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY3froVsvDVV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "db4035dd-7eae-4c3e-992d-2cf1927e0ba1"
      },
      "source": [
        "maxx,maxy=30,30\n",
        "def v2w(x):\n",
        "    return w2v.most_similar(positive=[x])[0][0]\n",
        "def predict(question,model):\n",
        "    qusetion=to_vec(question)\n",
        "    while len(qusetion)<maxx:\n",
        "        qusetion.append(v_end)\n",
        "    ans=[v_end for _ in range(maxy)]\n",
        "    ans[0]=v_start\n",
        "    for i in range(1,maxy):\n",
        "        ans[i]=model.predict([[qusetion],[ans]])[0][i-1]\n",
        "    text=[v2w(i) for i in ans]\n",
        "    return ' '.join(text)\n",
        "print(predict('',model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<start> 反正 無腦 ? ? <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfsMM2XmqXhO"
      },
      "source": [
        "def get_response(q):\n",
        "    a=predict(q,model)\n",
        "    return a.replace('<start> ','').replace(' <end>','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNxbopxIm4Mf"
      },
      "source": [
        "for q in questions:\n",
        "    print('=====================')\n",
        "    print(q)\n",
        "    print(predict(q,model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3e7SHLKpJxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "bd978e97-4247-424a-ae1c-8f97813353b6"
      },
      "source": [
        "while True:\n",
        "    print('Q: ')\n",
        "    q=input()\n",
        "    if q=='exit':\n",
        "        break\n",
        "    print('A: '+get_response(q))\n",
        "    print('==================')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q: \n",
            "統一有違反公平交易法嗎？\n",
            "A: 左打 味全 開單 很爽 ,\n",
            "==================\n",
            "Q: \n",
            "國語女歌手誰排第一？\n",
            "A: 阿妹 人氣 媽的\n",
            "==================\n",
            "Q: \n",
            "有車有房的車跟房的標準是??\n",
            "A: 兩百萬 ? ? ?\n",
            "==================\n",
            "Q: \n",
            "exit\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}